{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1176415,
          "sourceType": "datasetVersion",
          "datasetId": 667889
        }
      ],
      "dockerImageVersionId": 30396,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install ultralytics pyyaml\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import glob\n",
        "import yaml\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Mount Google Drive (upload your dataset to Drive first)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ================== PATHS CONFIGURATION ==================\n",
        "# Update these paths according to your dataset location\n",
        "DATASET_PATH = \"/content/drive/MyDrive/face-mask-detection\"\n",
        "IMAGE_DIR = os.path.join(DATASET_PATH, \"images\")\n",
        "ANNOTATION_DIR = os.path.join(DATASET_PATH, \"annotations\")\n",
        "\n",
        "# Output directories\n",
        "WORK_DIR = \"/content/datasets\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "\n",
        "# ================== DATA PROCESSING ==================\n",
        "# Load and parse annotations\n",
        "annotations = list(Path(ANNOTATION_DIR).glob(r'**/*.xml'))\n",
        "\n",
        "class_id = {\n",
        "    \"with_mask\": 0,\n",
        "    \"mask_weared_incorrect\": 1,\n",
        "    \"without_mask\": 2\n",
        "}\n",
        "\n",
        "data_dict = {\n",
        "    'filename': [], 'label': [], 'class_id': [],\n",
        "    'width': [], 'height': [], 'bboxes': []\n",
        "}\n",
        "\n",
        "for annotation_path in annotations:\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "    filename = root.find('filename').text\n",
        "\n",
        "    for obj in root.findall(\"object\"):\n",
        "        label = obj.find(\"name\").text\n",
        "        bndbox = obj.find('bndbox')\n",
        "\n",
        "        bbox = [\n",
        "            int(bndbox.find('xmin').text),\n",
        "            int(bndbox.find('ymin').text),\n",
        "            int(bndbox.find('xmax').text),\n",
        "            int(bndbox.find('ymax').text)\n",
        "        ]\n",
        "\n",
        "        size = root.find('size')\n",
        "        data_dict['filename'].append(filename)\n",
        "        data_dict['width'].append(int(size.find('width').text))\n",
        "        data_dict['height'].append(int(size.find('height').text))\n",
        "        data_dict['label'].append(label)\n",
        "        data_dict['class_id'].append(class_id[label])\n",
        "        data_dict['bboxes'].append(bbox)\n",
        "\n",
        "df_data = pd.DataFrame(data_dict)\n",
        "\n",
        "# ================== DATA SPLITTING ==================\n",
        "# Create train/val/test directories\n",
        "train_path = os.path.join(WORK_DIR, \"train\")\n",
        "valid_path = os.path.join(WORK_DIR, \"valid\")\n",
        "test_path = os.path.join(WORK_DIR, \"test\")\n",
        "\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(valid_path, exist_ok=True)\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# Split dataset\n",
        "train_files, test_files = train_test_split(df_data.filename.unique(), test_size=0.2, random_state=23)\n",
        "train_files, valid_files = train_test_split(train_files, test_size=0.15, random_state=23)\n",
        "\n",
        "# ================== DATA PREPARATION ==================\n",
        "def pascal_voc_to_yolo(bbox, img_w, img_h):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = ((x_min + x_max) / 2) / img_w\n",
        "    y_center = ((y_min + y_max) / 2) / img_h\n",
        "    width = (x_max - x_min) / img_w\n",
        "    height = (y_max - y_min) / img_h\n",
        "    return [x_center, y_center, width, height]\n",
        "\n",
        "def prepare_dataset(files, target_dir):\n",
        "    # Copy images\n",
        "    for file in files:\n",
        "        src = os.path.join(IMAGE_DIR, file)\n",
        "        dst = os.path.join(target_dir, file)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    # Create labels\n",
        "    for file in files:\n",
        "        file_stem = Path(file).stem\n",
        "        label_path = os.path.join(target_dir, f\"{file_stem}.txt\")\n",
        "\n",
        "        file_data = df_data[df_data['filename'] == file]\n",
        "        with open(label_path, 'w') as f:\n",
        "            for _, row in file_data.iterrows():\n",
        "                yolo_bbox = pascal_voc_to_yolo(row['bboxes'], row['width'], row['height'])\n",
        "                line = f\"{row['class_id']} {' '.join(map(str, yolo_bbox))}\"\n",
        "                f.write(line + '\\n')\n",
        "\n",
        "# Prepare all datasets\n",
        "prepare_dataset(train_files, train_path)\n",
        "prepare_dataset(valid_files, valid_path)\n",
        "prepare_dataset(test_files, test_path)\n",
        "\n",
        "# ================== YAML CONFIG ==================\n",
        "yaml_content = f\"\"\"\n",
        "train: {train_path}\n",
        "val: {valid_path}\n",
        "test: {test_path}\n",
        "nc: 3\n",
        "names: {list(class_id.keys())}\n",
        "\"\"\"\n",
        "\n",
        "with open('facemask.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "# ================== TRAINING ==================\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "model.train(data=\"facemask.yaml\", epochs=20, project=\"/content/runs\")\n",
        "\n",
        "# ================== VALIDATION ==================\n",
        "model.val(data=\"facemask.yaml\")\n",
        "\n",
        "# ================== PREDICTION ==================\n",
        "test_images = glob.glob(os.path.join(test_path, \"*.png\"))\n",
        "results = model.predict(test_images, save=True, project=\"/content/runs/predictions\")\n",
        "\n",
        "# Display predictions\n",
        "for img_path in glob.glob(\"/content/runs/predictions/*.jpg\"):\n",
        "    img = Image.open(img_path)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ny9Qmt3z4p",
        "outputId": "5578487a-fb7b-429d-be1c-0c8f37f25b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.128)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ultralytics 8.3.128 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=facemask.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2934.1Â±842.1 MB/s, size: 344.7 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/train... 579 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 579/579 [00:00<00:00, 762.91it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/train.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3039.0Â±925.5 MB/s, size: 401.2 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/valid... 103 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 802.11it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/valid.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/runs/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/20         0G      1.644      2.688      1.365         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:42<00:00, 14.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:30<00:00,  7.55s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.011      0.398      0.205      0.122\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/20         0G      1.322      1.468       1.08         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:40<00:00, 14.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.06s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.984     0.0896      0.292      0.178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/20         0G      1.294      1.275      1.076         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:27<00:00, 13.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.495      0.363      0.461       0.27\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/20         0G      1.254      1.184      1.065         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:29<00:00, 13.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.612      0.506      0.529      0.326\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/20         0G      1.181      1.074       1.04         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:27<00:00, 13.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.641      0.556      0.583       0.36\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/20         0G        1.2      1.023      1.036         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:27<00:00, 13.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.38s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.673      0.537      0.606      0.373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/20         0G      1.166     0.9464      1.011         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:32<00:00, 13.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.636      0.536      0.591      0.368\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/20         0G      1.148     0.9034      1.019         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:31<00:00, 13.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615       0.72      0.582      0.651      0.408\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/20         0G      1.127     0.8621      1.008         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:30<00:00, 13.79s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.05s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.718      0.655      0.692      0.426\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/20         0G      1.108      0.859       1.01         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:18<00:00, 13.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.684      0.652      0.695      0.443\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/20         0G      1.089     0.8975      1.005          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:30<00:00, 13.80s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:27<00:00,  6.96s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.895      0.528      0.667      0.425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/20         0G      1.066      0.825     0.9917         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:16<00:00, 13.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.752      0.656      0.706      0.441\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/20         0G      1.069     0.7738      0.995          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:18<00:00, 13.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.18s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.816      0.633      0.753      0.455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/20         0G      1.027     0.7449     0.9737          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:28<00:00, 13.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.768      0.694       0.76      0.471\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/20         0G       1.05     0.7282     0.9834          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:22<00:00, 13.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.788      0.655      0.737      0.466\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/20         0G      1.005     0.6978      0.976          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:18<00:00, 13.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.11s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.877      0.661      0.749      0.478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/20         0G     0.9984     0.6912     0.9682          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:29<00:00, 13.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.04s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.885       0.64      0.757      0.475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/20         0G      1.009     0.6594     0.9555         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:19<00:00, 13.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.24s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.872      0.673      0.777        0.5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/20         0G     0.9824     0.6349      0.955         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:17<00:00, 13.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615       0.93      0.647      0.778      0.489\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/20         0G     0.9649     0.6252      0.957          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [08:34<00:00, 13.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:30<00:00,  7.70s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.804      0.759      0.799      0.503\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "20 epochs completed in 2.979 hours.\n",
            "Optimizer stripped from /content/runs/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/train/weights/best.pt...\n",
            "Ultralytics 8.3.128 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:25<00:00,  6.31s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        103        615      0.803      0.762      0.799      0.503\n",
            "             with_mask         97        455      0.832      0.914      0.936      0.644\n",
            " mask_weared_incorrect         14         23      0.805       0.54      0.603      0.353\n",
            "          without_mask         36        137      0.772      0.832      0.859      0.512\n",
            "Speed: 2.8ms preprocess, 208.1ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train\u001b[0m\n",
            "Ultralytics 8.3.128 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1278.3Â±429.6 MB/s, size: 541.1 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/valid.cache... 103 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:26<00:00,  3.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        103        615      0.792      0.738      0.796      0.502\n",
            "             with_mask         97        455      0.832      0.912      0.934      0.643\n",
            " mask_weared_incorrect         14         23      0.784      0.478      0.597      0.351\n",
            "          without_mask         36        137      0.759      0.825      0.855      0.511\n",
            "Speed: 1.8ms preprocess, 210.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train2\u001b[0m\n",
            "\n",
            "0: 640x640 1 with_mask, 358.4ms\n",
            "1: 640x640 1 with_mask, 358.4ms\n",
            "2: 640x640 2 with_masks, 358.4ms\n",
            "3: 640x640 1 with_mask, 358.4ms\n",
            "4: 640x640 20 with_masks, 1 mask_weared_incorrect, 2 without_masks, 358.4ms\n",
            "5: 640x640 1 without_mask, 358.4ms\n",
            "6: 640x640 2 with_masks, 358.4ms\n",
            "7: 640x640 4 with_masks, 358.4ms\n",
            "8: 640x640 8 with_masks, 4 without_masks, 358.4ms\n",
            "9: 640x640 1 with_mask, 358.4ms\n",
            "10: 640x640 1 with_mask, 358.4ms\n",
            "11: 640x640 3 with_masks, 1 without_mask, 358.4ms\n",
            "12: 640x640 3 with_masks, 1 without_mask, 358.4ms\n",
            "13: 640x640 7 with_masks, 3 without_masks, 358.4ms\n",
            "14: 640x640 9 with_masks, 3 without_masks, 358.4ms\n",
            "15: 640x640 1 without_mask, 358.4ms\n",
            "16: 640x640 3 with_masks, 1 without_mask, 358.4ms\n",
            "17: 640x640 8 with_masks, 358.4ms\n",
            "18: 640x640 1 without_mask, 358.4ms\n",
            "19: 640x640 1 with_mask, 358.4ms\n",
            "20: 640x640 1 with_mask, 358.4ms\n",
            "21: 640x640 1 with_mask, 2 without_masks, 358.4ms\n",
            "22: 640x640 3 with_masks, 358.4ms\n",
            "23: 640x640 1 without_mask, 358.4ms\n",
            "24: 640x640 5 with_masks, 1 without_mask, 358.4ms\n",
            "25: 640x640 5 with_masks, 358.4ms\n",
            "26: 640x640 5 with_masks, 1 mask_weared_incorrect, 358.4ms\n",
            "27: 640x640 13 with_masks, 358.4ms\n",
            "28: 640x640 5 with_masks, 358.4ms\n",
            "29: 640x640 1 with_mask, 358.4ms\n",
            "30: 640x640 5 with_masks, 8 without_masks, 358.4ms\n",
            "31: 640x640 1 with_mask, 358.4ms\n",
            "32: 640x640 1 mask_weared_incorrect, 1 without_mask, 358.4ms\n",
            "33: 640x640 1 with_mask, 358.4ms\n",
            "34: 640x640 1 without_mask, 358.4ms\n",
            "35: 640x640 4 with_masks, 2 without_masks, 358.4ms\n",
            "36: 640x640 1 with_mask, 358.4ms\n",
            "37: 640x640 7 with_masks, 1 mask_weared_incorrect, 7 without_masks, 358.4ms\n",
            "38: 640x640 2 with_masks, 358.4ms\n",
            "39: 640x640 1 with_mask, 358.4ms\n",
            "40: 640x640 2 with_masks, 358.4ms\n",
            "41: 640x640 3 with_masks, 358.4ms\n",
            "42: 640x640 1 without_mask, 358.4ms\n",
            "43: 640x640 13 with_masks, 358.4ms\n",
            "44: 640x640 7 with_masks, 1 without_mask, 358.4ms\n",
            "45: 640x640 2 with_masks, 1 mask_weared_incorrect, 6 without_masks, 358.4ms\n",
            "46: 640x640 1 with_mask, 358.4ms\n",
            "47: 640x640 2 with_masks, 358.4ms\n",
            "48: 640x640 1 without_mask, 358.4ms\n",
            "49: 640x640 1 mask_weared_incorrect, 358.4ms\n",
            "50: 640x640 1 with_mask, 358.4ms\n",
            "51: 640x640 5 with_masks, 1 without_mask, 358.4ms\n",
            "52: 640x640 4 with_masks, 1 without_mask, 358.4ms\n",
            "53: 640x640 1 without_mask, 358.4ms\n",
            "54: 640x640 8 with_masks, 358.4ms\n",
            "55: 640x640 1 with_mask, 358.4ms\n",
            "56: 640x640 6 with_masks, 358.4ms\n",
            "57: 640x640 4 with_masks, 1 without_mask, 358.4ms\n",
            "58: 640x640 2 with_masks, 358.4ms\n",
            "59: 640x640 2 with_masks, 358.4ms\n",
            "60: 640x640 4 with_masks, 358.4ms\n",
            "61: 640x640 2 with_masks, 358.4ms\n",
            "62: 640x640 1 without_mask, 358.4ms\n",
            "63: 640x640 6 with_masks, 2 without_masks, 358.4ms\n",
            "64: 640x640 1 with_mask, 358.4ms\n",
            "65: 640x640 2 with_masks, 358.4ms\n",
            "66: 640x640 1 with_mask, 358.4ms\n",
            "67: 640x640 1 with_mask, 2 without_masks, 358.4ms\n",
            "68: 640x640 42 with_masks, 2 without_masks, 358.4ms\n",
            "69: 640x640 1 with_mask, 2 without_masks, 358.4ms\n",
            "70: 640x640 1 with_mask, 358.4ms\n",
            "71: 640x640 (no detections), 358.4ms\n",
            "72: 640x640 85 with_masks, 11 without_masks, 358.4ms\n",
            "73: 640x640 11 with_masks, 2 without_masks, 358.4ms\n",
            "74: 640x640 2 with_masks, 1 without_mask, 358.4ms\n",
            "75: 640x640 1 with_mask, 358.4ms\n",
            "76: 640x640 1 without_mask, 358.4ms\n",
            "77: 640x640 6 with_masks, 1 mask_weared_incorrect, 358.4ms\n",
            "78: 640x640 1 with_mask, 358.4ms\n",
            "79: 640x640 1 with_mask, 358.4ms\n",
            "80: 640x640 5 with_masks, 358.4ms\n",
            "81: 640x640 1 with_mask, 358.4ms\n",
            "82: 640x640 4 with_masks, 358.4ms\n",
            "83: 640x640 18 with_masks, 1 mask_weared_incorrect, 2 without_masks, 358.4ms\n",
            "84: 640x640 3 with_masks, 358.4ms\n",
            "85: 640x640 5 with_masks, 358.4ms\n",
            "86: 640x640 23 with_masks, 2 mask_weared_incorrects, 1 without_mask, 358.4ms\n",
            "87: 640x640 15 with_masks, 358.4ms\n",
            "88: 640x640 3 with_masks, 358.4ms\n",
            "89: 640x640 1 with_mask, 358.4ms\n",
            "90: 640x640 12 with_masks, 19 without_masks, 358.4ms\n",
            "91: 640x640 6 with_masks, 3 without_masks, 358.4ms\n",
            "92: 640x640 4 with_masks, 1 without_mask, 358.4ms\n",
            "93: 640x640 1 with_mask, 5 without_masks, 358.4ms\n",
            "94: 640x640 1 with_mask, 358.4ms\n",
            "95: 640x640 1 with_mask, 358.4ms\n",
            "96: 640x640 1 with_mask, 358.4ms\n",
            "97: 640x640 5 with_masks, 358.4ms\n",
            "98: 640x640 4 with_masks, 358.4ms\n",
            "99: 640x640 1 with_mask, 2 without_masks, 358.4ms\n",
            "100: 640x640 1 without_mask, 358.4ms\n",
            "101: 640x640 12 with_masks, 4 without_masks, 358.4ms\n",
            "102: 640x640 2 with_masks, 12 without_masks, 358.4ms\n",
            "103: 640x640 1 without_mask, 358.4ms\n",
            "104: 640x640 1 with_mask, 358.4ms\n",
            "105: 640x640 4 with_masks, 3 without_masks, 358.4ms\n",
            "106: 640x640 2 with_masks, 358.4ms\n",
            "107: 640x640 1 with_mask, 358.4ms\n",
            "108: 640x640 1 with_mask, 1 without_mask, 358.4ms\n",
            "109: 640x640 1 with_mask, 358.4ms\n",
            "110: 640x640 7 with_masks, 1 without_mask, 358.4ms\n",
            "111: 640x640 1 with_mask, 358.4ms\n",
            "112: 640x640 1 with_mask, 358.4ms\n",
            "113: 640x640 8 with_masks, 358.4ms\n",
            "114: 640x640 1 with_mask, 358.4ms\n",
            "115: 640x640 1 without_mask, 358.4ms\n",
            "116: 640x640 1 with_mask, 358.4ms\n",
            "117: 640x640 1 without_mask, 358.4ms\n",
            "118: 640x640 4 with_masks, 358.4ms\n",
            "119: 640x640 1 with_mask, 358.4ms\n",
            "120: 640x640 2 with_masks, 1 mask_weared_incorrect, 358.4ms\n",
            "121: 640x640 18 with_masks, 3 without_masks, 358.4ms\n",
            "122: 640x640 3 with_masks, 358.4ms\n",
            "123: 640x640 24 with_masks, 358.4ms\n",
            "124: 640x640 3 with_masks, 358.4ms\n",
            "125: 640x640 6 with_masks, 1 without_mask, 358.4ms\n",
            "126: 640x640 2 with_masks, 2 without_masks, 358.4ms\n",
            "127: 640x640 1 without_mask, 358.4ms\n",
            "128: 640x640 4 with_masks, 358.4ms\n",
            "129: 640x640 2 with_masks, 358.4ms\n",
            "130: 640x640 5 with_masks, 1 mask_weared_incorrect, 2 without_masks, 358.4ms\n",
            "131: 640x640 1 with_mask, 358.4ms\n",
            "132: 640x640 1 with_mask, 358.4ms\n",
            "133: 640x640 3 with_masks, 1 without_mask, 358.4ms\n",
            "134: 640x640 1 without_mask, 358.4ms\n",
            "135: 640x640 1 with_mask, 358.4ms\n",
            "136: 640x640 10 with_masks, 1 without_mask, 358.4ms\n",
            "137: 640x640 9 with_masks, 358.4ms\n",
            "138: 640x640 2 with_masks, 358.4ms\n",
            "139: 640x640 2 with_masks, 358.4ms\n",
            "140: 640x640 12 with_masks, 2 mask_weared_incorrects, 4 without_masks, 358.4ms\n",
            "141: 640x640 2 with_masks, 358.4ms\n",
            "142: 640x640 1 with_mask, 358.4ms\n",
            "143: 640x640 3 with_masks, 1 without_mask, 358.4ms\n",
            "144: 640x640 1 with_mask, 358.4ms\n",
            "145: 640x640 2 with_masks, 358.4ms\n",
            "146: 640x640 5 with_masks, 358.4ms\n",
            "147: 640x640 1 with_mask, 358.4ms\n",
            "148: 640x640 5 with_masks, 358.4ms\n",
            "149: 640x640 1 without_mask, 358.4ms\n",
            "150: 640x640 4 with_masks, 3 without_masks, 358.4ms\n",
            "151: 640x640 4 with_masks, 358.4ms\n",
            "152: 640x640 1 with_mask, 358.4ms\n",
            "153: 640x640 1 with_mask, 358.4ms\n",
            "154: 640x640 2 with_masks, 358.4ms\n",
            "155: 640x640 1 without_mask, 358.4ms\n",
            "156: 640x640 1 with_mask, 358.4ms\n",
            "157: 640x640 4 with_masks, 358.4ms\n",
            "158: 640x640 4 with_masks, 358.4ms\n",
            "159: 640x640 2 with_masks, 1 without_mask, 358.4ms\n",
            "160: 640x640 6 with_masks, 358.4ms\n",
            "161: 640x640 1 with_mask, 358.4ms\n",
            "162: 640x640 1 with_mask, 358.4ms\n",
            "163: 640x640 18 with_masks, 1 mask_weared_incorrect, 1 without_mask, 358.4ms\n",
            "164: 640x640 18 with_masks, 1 without_mask, 358.4ms\n",
            "165: 640x640 7 with_masks, 1 without_mask, 358.4ms\n",
            "166: 640x640 13 with_masks, 2 without_masks, 358.4ms\n",
            "167: 640x640 1 with_mask, 358.4ms\n",
            "168: 640x640 2 with_masks, 358.4ms\n",
            "169: 640x640 4 with_masks, 1 without_mask, 358.4ms\n",
            "170: 640x640 1 with_mask, 358.4ms\n",
            "Speed: 19.2ms preprocess, 358.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/predictions/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWL6FQxr348B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}